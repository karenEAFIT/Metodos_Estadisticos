---
title: <center><h1> **TRABAJO FINAL MÉTODOS ESTADÍSTICOS AVANZADOS** </h1> </center>
subtitle: <center> Caracterización de la relación entre el costo de ventas y las variables macroeconómicas colombianas </center>
author: <center> Ana María Urán González - Karen Lizeth Velásquez Moná </center>
date: <center>Mayo de 2020 </center>
output: html_document

---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### **I.Introducción**
<div class=text-justify>
Durante los últimos años   se ha  visto como  el sector de la  construcción se  ha ganado un papel protagónico debido al dinamismo que  genera en la economía nacional. No obstante, la construcción es  un sector que se ha caracterizado  históricamente  por  sus  fluctuaciones, entre 1980-2019 el PIB de  la construcción  han tenido  ciclos que  involucran fases de  expansión  y recesión, para  ser más  exactos entre 2016-2019 el sector  ha experimentado caídas  hasta de  -0.1%  debido a las grandes dificultades que ha venido sorteando, como la  sobreoferta de proyecto, la caída en la  demanda  debido al aumento de las  tasas de  interés, la incertidumbre política en la que  se ha visto inmerso el país y la volatilidad en los  mercados cambiarios mundiales.

Uno  de los subsectores  que  mayor  importancia  tiene  es el de la construcción de  edificaciones  residenciales, pues  no solo aporta en  temas de bienestar social construyendo  viviendas, sino que  también es uno de los  que mayor número de  empleos directos  e  indirectos  genera. Sin embargo,los periodos de recesión del sector lo afectan fuertemente debido a las  variaciones en los  precios  del  dólar que  afecta los precios de los  acabados importados  para proyectos en estratos altos, adicionalmente,  los  incrementos en las tasas de  interés y el desempleo hacen que  las  personas  desistan  de  invertir  en  bienes durables  como vivienda. Todo lo anterior  hace  que las  empresas  constructoras necesiten invertir más  dinero en la  construcción  y divulgación del proyecto incrementando así los costos  de  venta  en los cuales  deben incurrir.

Con base en  el contexto anterior, se  quiere caracterizar la relación que  existe  entre  el costo de  ventas del subsector de construcción de  edificaciones  y las variables  macroenomicas  del país por medio de modelos  lineales  y bajo  los procesos de consolidación de  información que se  exponen a continuación.
</div>

### **II.Consolidación de información**
<div class=text-justify>
Uno de  los pasos  para la realización de  un análisis que mayor tiempo demanda  es la consolidación de la base de  datos. En nuestro  caso de  estudio, era necesario  ubicar la información de las  constructoras,  para  ello se  tomaron  los estados de  resultados de las  empresas publicados  en la  página de  la [superintendencia de sociedades]( http://pie.supersociedades.gov.co/Pages/default.aspx#/), allí se encontraron dificultades como el cambio de estructura entre los archivos de un año a otro y duplicidad o ausencia  de información para una empresa en un periodo de tiempo. Finalmente  se  seleccionaron 73 constructoras de residencias las  cuales  tenían la información de  interés  completa para el periodo 2016-2018, dicha  información era:

  * Nit
  * Periodo  
  * Departamento
  * Costos de  venta 
  * Ventas
  * Pasivos corrientes totales
  * Activos Corrientes totales


Definidos los  individuos  del estudio (empresas) y su información más  relevante, es necesario  buscar la  información macroeconómica, para esto  se consultaron  los  informes  oficiales  publicados en las  páginas  web del  [banco de la republica ]( https://www.banrep.gov.co/es/-estadisticas), el [DANE]( https://www.dane.gov.co/index.php/estadisticas-por-tema)  y la [Contraloría](https://www.contraloria.gov.co/web/finanzas-publicas/ley-617-de-20001). Estos indicadores pueden ser  medidos  de manera mensual, trimestral  o diaria, se  tomó el dato  correspondiente al cierre  de cada año de  estudio  y se construyeron las  siguientes  variables  para el análisis:

  * Variación anual PIB nacional
  * PIB departamental
  * Variación anual PIB departamental 
  * Variación anual de la  tasa de interés
  * Tasa de interés promedio
  * Variación anual de la cuenta corriente  nacional 
  * Ingresos cuenta corriente  departamental
  * Gastos  de funcionamiento departamental
  * Variación  anual de la inflación nacional
  * Inflación  anual nacional
  * Variación  anual de la TRM
  * Tasa de  desempleo nacional 
  * Tasa de  desempleo departamental
  * IPC nacional
  * IPC departamental

Adicionalmente, se  consideraron  variables propias  del  sector como:

  * Cartera Hipotecaria  de Vivienda (CHV)
  * Variación en la Cartera Hipotecaria  de Vivienda (CHV)
  * Estadística de Concreto (EC)  
  * Variación en la Estadística de Concreto (EC)
  * Variación de Índice de Financiación de Vivienda (FIVI)
  * Variación en el Índice de Costos de la Construcción de Vivienda (ICCV)
  * Variación del Índice de  Variación Predial (IVP)
  * Variación del índice de Precios de Vivienda Nueva (IPVN)
  * Estadísticas de Cemento Gris (ECG)
  
Con el  fin de  disminuir  la variabilidad  entre las empresas debido a su diferencia  en tamaño, se   transformarán las  variables  *Costos de Venta* y *Ventas* en la variable *Proporción*, la cual  medirá  la  proporción del costo de  cada empresa *i* con  respecto a sus ventas  en el periodo *t*.

$$proporcion{_i}{_t} = \frac{costos{_i}{_t}}{ventas{_i}{_t}}$$
Adicionalmente se considera importante conocer la solidez de la empresa para determinar  si esta tiene capacidad de convertir sus activos en liquidez a corto plazo, Asi que, transformaremos las variables *Activos corrientes totales* y *Pasivos corrientes totales* en el indicador *liquidez*  para cada empresa *i* en el  periodo *t*.
$$liquidez{_i}{_t} = \frac{ActivosCorrientesTotales{_i}{_t}}{PasivosCorrientesTotales{_i}{_t}}$$
Estas  variables  transformadas son incluidas al conjunto de  datos  original.Con la base de datos construida se realizarán 2 planteamientos diferentes  para  intentar caracterizar la relación de los costos  de  venta y las variables macroeconomicas, en el primero tomaremos solo las  variables de corte  nacional, mientras  que en el segundo repetiremos el ejercicio con algunas  de las  variables a corte departamental de tal manera que podamos  determinar si un enfoque  departamental es más util para determinar  esta relación. Adicionalmente, en ambos  casos emplearemos modelos de  efectos mixtos donde tomaremos  como  variable  factor cada  cada empresa.
</div>

### **III.Primer enfoque:Analisis con información nacional**

#### **a.Exploración de datos**
<div class=text-justify>
Iniciaremos realizando un análisis exploratorio  para el siguiente  conjunto de  datos:

|    Variables                               |
|----------------------|---------------------|
|nit                   |EC_Variacion         |
|periodo               |FIVI_Variacion       |
|costos                |ICCV_Variacion       |
|Proporcion            |IVP_Variacion        |
|liquidez              |IPVN_Variacion       |
|PIB_Variacion         |Inflacion_Variacion  |  
|variacion_tas_int     |TRM_Variación        |
|variacion_cta_corr_nal|Tasa_Desempleo       |
|CHV_variacion         |IPC                  |


```{r include=FALSE}
library(kableExtra) 
library(readxl)
library(tidyverse)
datosp <- read_excel("Datos_definitivos.xlsx")
datosp <- datosp[,c("nit","periodo","costos","Proporcion","liquidez","PIB_Variacion","variacion_tas_int","variacion_cta_corr_nal","CHV_variacion","EC_Variacion","FIVI_Variacion","ICCV_Variacion","IVP_Variacion","IPVN_Variacion","Inflacion_Variacion","TRM_Variación","Tasa_Desempleo","IPC")]

```


```{r echo=FALSE}
bxplot_gastos_dif = boxplot(datosp$Proporcion~datosp$periodo , 
        main = "Proporción vs periodo",
        xlab = "Periodos",
        ylab = "Proporción",
        boxwex = 0.5,col="dodgerblue")
```

Logramos identificar que existen outliers en cada uno de los periodos por lo cual estos serán excluidos.Revisando a detalle estas observaciones  vemos que  son aquellas  donde la proporción entre  costos de ventas y ventas es bastante baja y que  no tienen lugar en la realidad del  mercado para este sector. De esta manera,eliminaremos  aquellas porporciones que se  encuentrán por debajo del primer decil.
</div>

```{r include=FALSE}
impute_outliers <- function(x, removeNA = TRUE){
  quantiles <- quantile(x, c(0.05, 0.95), na.rm = removeNA)
  x[x<quantiles[1]] <- mean(x, na.rm = removeNA)
  x[x>quantiles[2]] <- median(x, na.rm = removeNA)
  x
}

datos_16   <- datosp %>%             # a partir de out.predict.garch  
  filter(datosp$periodo==2016)


out16 <- datos_16 %>%             # a partir de out.predict.garch  
  filter(datos_16$Proporcion <= quantile(datos_16$Proporcion, c(0.10)))


datos_17   <- datosp %>%             # a partir de out.predict.garch  
  filter(datosp$periodo==2017)

out17 <- datos_17 %>%             # a partir de out.predict.garch  
  filter(datos_17$Proporcion <= quantile(datos_17$Proporcion, c(0.10)))


datos_18   <- datosp %>%             # a partir de out.predict.garch  
  filter(datosp$periodo==2018)


out18 <- datos_18 %>%             # a partir de out.predict.garch  
  filter(datos_18$Proporcion <= quantile(datos_18$Proporcion, c(0.10)))


out16 = t(out16$nit)
out17 = t(out17$nit)
out18 = t(out18$nit)

outliers = distinct(as.data.frame(t(cbind(out16,out17,out18))))
names(outliers) = ("Nit_Out")

```

Los datos  outlier corresponden a 17 empresas las  cuales sacaremos apartir de  este momento del analisis, esto con el fin de  conservar  un conjunto de  datos donde  cada individuo cuente  con las  mediciones en los  3 periodos  de  tiempo.

```{r echo=FALSE}
`%ni%` <- Negate(`%in%`)
out = datosp$nit%ni%outliers$Nit_Out
datos_sop = datosp[out,]
boxplot(datos_sop$Proporcion~datos_sop$periodo,
        main = "Proporción vs periodo sin outliers",
        xlab = "Periodos",
        ylab = "Proporción",
        boxwex = 0.5,col="dodgerblue3")
```

#### **b.Proceso de modelado**
##### <span style="color:#404d78"> **División de datos en entrenamiento y test** </span>
<div class=text-justify>
Como se mencionó anteriormente,para abordar  este  problema se emplearán los  modelos de  efectos  mixtos. Este tipo de modelos  estadísticos requieren  el uso de  niveles  de agrupación,para este caso serán las empresas.El conjunto de entrenamiento  tomará todos los  nits y dejará solo un 20% de ellas  con solo  2 mediciones (2016-2017) almacenando así la infomación de 2018  como base de testeo.
</div>

```{r include=FALSE}
datos_sop$periodo = factor(datos_sop$periodo,
                       levels = c("2016","2017","2018"),
                       labels = c(1,2,3))
datos_sop$nit = factor(datos_sop$nit)
```

```{r include=FALSE}
library(caTools)
set.seed(4)
nite = as.data.frame(unique(datos_sop$nit))
names(nite) = c("nit")
split = sample.split(nite$nit, SplitRatio = 0.8)
training_set_p = subset(nite, split == TRUE)
training_set_p = datos_sop$nit%in%training_set_p$nit
training_set_p = datos_sop[training_set_p,]
testing_set_p = subset(nite, split == FALSE)
testing_set_p = datos_sop$nit%in%testing_set_p$nit
testing_set_p = datos_sop[testing_set_p,]
periodo_test = c(3)
testing_p = testing_set_p$periodo%in%periodo_test
testing_set_ = testing_set_p[testing_p,]
periodo_train = c(1,2)
train_p = testing_set_p$periodo%in%periodo_train
train_p = testing_set_p[train_p,]
training_set_p = rbind(training_set_p,train_p)
```

```{r echo=FALSE}
cantidad <- as.data.frame(cbind(12,50))
names(cantidad) = c("Cantidad empresas testeo","Cantidad empresas entrenamiento")

kable(cantidad) %>%
   kable_styling()%>%
  column_spec(1:1, bold = T) %>%
  row_spec(0, bold = T, color = "white", background = "#404d78")

```


##### <span style="color:#404d78"> **Planteamiento de modelos** </span>
<div class=text-justify>
Se sabe que existe una estrecha relación entre todas las  variables macroeconómicas por lo cual,dejarlas  todas  en un mismo  modelo  genera problemas de singularidad, es por esto que se  decide  crear  varios  modelos tomando solo algunas  de  estas variables.
Finalmente, logran consolidarse 6 modelos cantidatos para  explicar dicha relación,la estructura de los modelos entrenamos y sus métricas  de  calidad  se  exponen en la  siguiente  tabla:

```{r ,include=FALSE}
library(nlme)
modelo1 <- lme(Proporcion ~ PIB_Variacion+Inflacion_Variacion, data = training_set_p, random = ~1 | nit )
modelo2 <- lme(log(Proporcion) ~ Tasa_Desempleo+TRM_Variación+liquidez, data = training_set_p, random = ~1 | nit )
modelo3 <- lme(Proporcion ~ Tasa_Desempleo+TRM_Variación+liquidez, data = training_set_p, random = ~1 | nit )
modelo4 <- lme(Proporcion ~ PIB_Variacion+Tasa_Desempleo, data = training_set_p, random = ~1 | nit )
modelo5 <- lme(Proporcion ~ Tasa_Desempleo+  IPC +liquidez, data = training_set_p, random = ~1 | nit )
modelo6 <- lme(Proporcion ~ PIB_Variacion+ liquidez+Tasa_Desempleo, data = training_set_p, random = ~1 | nit )
Modelo <-  rbind("Modelo1","Modelo2","Modelo3","Modelo4","Modelo5","Modelo6")

AIC_Modelo <- rbind(round(AIC(modelo1),2),
round(AIC(modelo2),2),
round(AIC(modelo3),2),
round(AIC(modelo4),2),
round(AIC(modelo5),2),
round(AIC(modelo6),2))

BIC_Modelo <- rbind(round(BIC(modelo1),2),
round(BIC(modelo2),2),
round(BIC(modelo3),2),
round(BIC(modelo4),2),
round(BIC(modelo5),2),
round(BIC(modelo6),2))

estructura<-rbind("Proporcion ~ PIB_Variacion+Inflacion_Variacion+(1|nit)",
                  "log(Proporcion) ~ Tasa_Desempleo+TRM_Variación+liquidez+(1|nit)",
                  "Proporcion ~ Tasa_Desempleo+TRM_Variación+liquidez+(1|nit)",
                  "Proporcion ~ PIB_Variacion+Tasa_Desempleo+(1|nit)",
                  "Proporcion ~ Tasa_Desempleo+ IPC +liquidez+(1|nit)",
                  "Proporcion ~ PIB_Variacion+ liquidez+Tasa_Desempleo+(1|nit)")

metricas <- as.data.frame(cbind(Modelo,estructura,AIC_Modelo,BIC_Modelo))
names(metricas) = c("Modelo","Estructura","AIC","BIC")

```

```{r echo=FALSE}
kable(metricas) %>%
   kable_styling()%>%
  column_spec(1:1, bold = T) %>%
  row_spec(0, bold = T, color = "white", background = "#404d78")
```
<div class=text-justify>
Hasta  este  punto se  puede observar  que  según los criterios de AIC y BIC  el mejor modelo es el 4 ya que es el que  presenta menores valores  en ambos criterios, sin embargo, esto no es suficiente  para  seleccionarlo y es necesario conocer la capacidad predictiva y el ajuste de cada uno para  determinar  cual de ellos es  mejor.
</div>

```{r ,include=FALSE}
library(nlme)
library(MLmetrics)
prediccion1	=	predict(modelo1,testing_set_,level =1,allow.new.levels=T)
predichos1	=	cbind(testing_set_$Proporcion,as.data.frame(prediccion1))
names(predichos1)	=	c("Datos1","Prediccion1")
prediccion2	=	predict(modelo2,testing_set_,level =1,allow.new.levels=T)
predichos2	=	cbind(testing_set_$Proporcion,as.data.frame(prediccion2))
names(predichos2)	=	c("Datos2","Prediccion2")
prediccion3	=	predict(modelo3,testing_set_,level =1,allow.new.levels=T)
predichos3	=	cbind(testing_set_$Proporcion,as.data.frame(prediccion3))
names(predichos3)	=	c("Datos3","Prediccion3")
prediccion4	=	predict(modelo4,testing_set_,level =1,allow.new.levels=T)
predichos4	=	cbind(testing_set_$Proporcion,as.data.frame(prediccion4))
names(predichos4)	=	c("Datos4","Prediccion4")
prediccion5	=	predict(modelo5,testing_set_,level =1,allow.new.levels=T)
predichos5	=	cbind(testing_set_$Proporcion,as.data.frame(prediccion5))
names(predichos5)	=	c("Datos5","Prediccion5")
prediccion6	=	predict(modelo6,testing_set_,level =1,allow.new.levels=T)
predichos6	=	cbind(testing_set_$Proporcion,as.data.frame(prediccion6))
names(predichos6)	=	c("Datos6","Prediccion6")

MSE1<-MSE(predichos1$Prediccion1,predichos1$Datos1)
RMSE1<-RMSE(predichos1$Prediccion1,predichos1$Datos1)
MAPE1<-MAPE(predichos1$Prediccion1,predichos1$Datos1)
MSE2<-MSE(predichos2$Prediccion2,predichos2$Datos2)
RMSE2<-RMSE(predichos2$Prediccion2,predichos2$Datos2)
MAPE2<-MAPE(predichos2$Prediccion2,predichos2$Datos2)
MSE3<-MSE(predichos3$Prediccion3,predichos3$Datos3)
RMSE3<-RMSE(predichos3$Prediccion3,predichos3$Datos3)
MAPE3<-MAPE(predichos3$Prediccion3,predichos3$Datos3)
MSE4<-MSE(predichos4$Prediccion4,predichos4$Datos4)
RMSE4<-RMSE(predichos4$Prediccion4,predichos4$Datos4)
MAPE4<-MAPE(predichos4$Prediccion4,predichos4$Datos4)
MSE5<-MSE(predichos5$Prediccion5,predichos5$Datos5)
RMSE5<-RMSE(predichos5$Prediccion5,predichos5$Datos5)
MAPE5<-MAPE(predichos5$Prediccion5,predichos5$Datos5)
MSE6<-MSE(predichos6$Prediccion6,predichos6$Datos6)
RMSE6<-RMSE(predichos6$Prediccion6,predichos6$Datos6)
MAPE6<-MAPE(predichos6$Prediccion6,predichos6$Datos6)

RMSE <- rbind(round(RMSE1,6),
round(RMSE2,6),
round(RMSE3,6),
round(RMSE4,6),
round(RMSE5,6),
round(RMSE6,6))

MSE <- rbind(round(MSE1,6),
round(MSE2,6),
round(MSE3,6),
round(MSE4,6),
round(MSE5,6),
round(MSE6,6))

MAPE <- rbind(round(MAPE1,6),
round(MAPE2,6),
round(MAPE3,6),
round(MAPE4,6),
round(MAPE5,6),
round(MAPE6,6))

metricas_prediccion <- as.data.frame(cbind(MSE,RMSE,MAPE))
names(metricas_prediccion) = c("MSE","RMSE","MAPE")
metricas_consolidadas <- as.data.frame(cbind(metricas,metricas_prediccion))

```

```{r echo=FALSE}
kable(metricas_consolidadas) %>%
  kable_styling()%>%
  column_spec(1:1, bold = T) %>%
  row_spec(0, bold = T, color = "white", background = "#404d78")
```
<div class=text-justify>
En la tabla anterior vemos las  medidas de ajuste como el  MSE, el RMSE y  el MAPE de cada uno de modelos.
Se puede ver  como el  modelo 4 en el cual la proporción es  explicada por la  variación del PIB y la  tasa de desempleo posee unas  de  las  mejores métricas de ajuste. También es de  notar que  al incluir la  liquidez de la  empresa  como una de las  variables regresoras, las  estimaciones  desmejoran, pudiendose  concluir  que  la  liquidez no tiene  un efecto importante  en la variable  respuesta.
Ahora antes  de elegir el modelo 4 es necesario  revisar sus  residuales  con el  fin de  descartar patrones  contundentes en  su distribución.
<div>

```{r echo=FALSE}
plot(modelo4,type = c("p", "smooth"))
```

```{r echo=FALSE}
Fit <- fitted(modelo4)
Res <- residuals(modelo4, type = "normalized") 
par(mfrow = c(2, 2))
plot(Res ~ Fit, xlab = "Fitted values", ylab = "Residuals", main = "Residuals vs. fitted")
abline(h = 0)

hist(Res, main = "Histogram of residuals", xlab = "Residuals")
qqnorm(Res)
qqline(Res)

```

```{r echo=FALSE}
summary(modelo4)

```
Se  puede  ver  que  los  residuales  no  tienen  una  dispersión totalmente aletaria y que  no satisfacen  completamente el supuesto de normalidad, sin embargo, siendo el mejor  modelo entrenado  y considerando que aun con algunos  problemas  en sus residuales, sus  estimaciones  son buenas, seleccionaremos  el modelo  4 como nuestro modelo definitivo para el primer enfoque.

##### <span style="color:#404d78"> **Descripción del modelo seleccionado** </span>

La ecuación de  nuestro modelo  seleccionado es la siguiente:

$$Proporcion_{i t}= (0.8494852)+2.1121754*PIBVariacion_{i t}-1.1787256*TasaDesempleo_{i t}$$
De ella se puede interpretar que por cada 1% de variación en el PIB se espera que  la  proporción de ventas aumente en un 2.11% en la  empresa i para el periodo j,adicionalmente,una variación del 1% en la  tasa de  desempleo disminuye en un 1.18% la proporción de ventas  en la  empresa i para el periodo j. 

Ahora  veamos   como se  ve nuestro  modelo graficamente  aplicado a  cada NIT.

#### <span style="color:#404d78">** Recta de regresión ajustada** </span>

```{r echo=FALSE}
plot(modelo4, Proporcion ~ fitted(.) | nit, abline = c(0,1))
```

Vemos que la recta para los nits se ajusta bastante bien  a los datos por lo cual vemos una predicción bastante acertada.


### **IV.Segundo enfoque:Analisis con información departamental**
<div class=text-justify>
Si bien en el caso de estudio anterior logramos  determinar que existe una  relación entre la tasa de desempleo y la variación del PIB con la proporción entre el costos de ventas  y las  ventas de cada empresa,consideramos bastante relevante acompañar  estos  resultados, con un analisis por departamentos, para esto se  tomaron las  siguientes  variables de la base de datos:
<div >

|    Variables                               |
|----------------------|---------------------|
|nit                   |inflacion            |
|proporcion            |tasa_int_prom        |
|liquidez              |CHV                  |
|tasa_desemp_dep       |EC                   |
|pib_dep               |ECG                  |
|variacion_pib_dep     |gastos_fun_dep       |
|ipc_anio_dep          |ingr_corr_dep        |  


#### **a.Exploración de datos**
<div class=text-justify>
Para este caso se  seleccionaron variables con el dato macroeconómico puro, por esta razon es necesario  realizar estandarizaciones a las  variables explicativas, para centrarlas se tomaron valores referencia para cada variable de tal manera que  fuera facil si interpretación.
Asi las cosas las  variables  fueron  estandarizada tomando como referencia los  siguientes  valores:
<div>

|    Variables         |     Centro          |
|----------------------|---------------------|
|ingr_corr_dep         |1000000000           |
|gastos_fun_dep        |1000000000           |
|pib_dep               |100000               |
|CHV                   |100000               |
|ECG                   |1000000              |
|EC                    |1000000              | 
|tasa_desemp_dep       |10,5                 |
|variacion_pib_dep     | 1                   |
|ipc_anio_dep          | 2                   |
|inflacion             | 2                   |
|tasa_int_prom         | 0.055               |

```{r include=FALSE}
library(readxl)
datos <- read_excel("Departamentos.xlsx")
```

```{r include=FALSE}
datos$pib_dep=scale(datos$pib_dep, center=100000) #PIB departamento
datos$tasa_desemp_dep=scale(datos$tasa_desemp_dep,center=10,5) #tasa desempleo departamento
datos$ipc_anio_dep=scale(datos$ipc_anio_dep,center=2) #IPC anual departamento
datos$ingr_corr_dep=scale(datos$ingr_corr_dep,center=1000000000) # ingresos corrientes por  departamento
datos$gastos_fun_dep=scale(datos$gastos_fun_dep,center=1000000000) # gastos de  funcionamiento departamento
datos$inflacion=scale(datos$inflacion,center=2) # inflación nacional anual
datos$tasa_int_prom=scale(datos$tasa_int_prom) # Tasa de  intermediación bancaria promedio por año
datos$ingresos_nal=scale(datos$ingresos_nal, center=1000000000) #Ingreso nacionales
datos$gastos_nal=scale(datos$gastos_nal, center=1000000000)
datos$TRM=scale(datos$TRM, center=2500)
datos$variacion_pib_dep=scale(datos$variacion_pib_dep, center=1)
datos$intereses_nal=scale(datos$intereses_nal, center=100)
datos$CHV=scale(datos$CHV, center=100000)# Cartera hipotecaria Millones de pesos a precios corrientes
datos$EC=scale(datos$EC, center=1000000)# Concreto pre mezclado métros cúbicos
datos$ECG=scale(datos$ECG, center=1000000)# Cemento Gris toneladas
datos$EC_Variacion=scale(datos$EC_Variacion, center=1) #Variacion concreto pre mezclado
datos$ELIC_UND=scale(datos$ELIC_UND, center=10000) #EDIFICACIÓN LICENCIAS DE CONSTRUCCIÓN - ELIC  Unidades
datos$ELIC_AREA=scale(datos$ELIC_AREA, center=1000000) # Licencias de contronstruccion área metros cuadrados
datos$ICC_Variacion=scale(datos$ICC_Variacion, center=1) #Variacion de indice de costos de la construccion de vivienda
datos$ICCV_Indice=scale(datos$ICCV_Indice, center=1) #Indice de costos de la construccion de vivienda
datos$FIVI_Variacion=scale(datos$FIVI_Variacion, center=1) #Variación vivienda nueva
datos$IVP_Indice=scale(datos$IVP_Indice, center=100) #Indice de Valoracion predial
datos$IPVN_Indice=scale(datos$IPVN_Indice, center=100) #Indice de precios de vivienda nueva
datos$IPP_Manufactura=scale(datos$IPP_Manufactura, center=100) #Indice de precios al productor

```
<div class=text-justify>
  Ahora, realizaremos una  revisión de los perfiles por departamento, con el  fin de  encontrar  información adicional que pueda  servirnos para  refinar nuestros analisis.
<div>
```{r echo=TRUE}

library(lattice)
xyplot(proporcion ~ periodo | Departamento , groups = nit, data = datos, type = "l", lty = 1) 
```
<div class=text-justify>
  En el gráfico anterior podemos observar que Bogotá es el pricipal centro de de  ubicación de las  constructoras de vivienda, seguida de Antioquia, Santander  y Valle.Tambien  se  evidencia que  en  regiones  como Boyacá,Caldas,Sucre, Quindio,Córdoba,Magdalena,Meta no existe un gran número de competidores. Este hallazgo nos  motiva a tomar  la  decisión de  centrar  nuestro analisis solo en aquellos  departamentos que  poseen mas  de 3 empresas en el mercado.
<div>

```{r include=FALSE}
library(dplyr)
grupos <- group_by(datos, Departamento)
grupo <- summarise(grupos,
  num = n()
)

library(tidyverse)

Departamentos   <- grupo %>%  
  filter(grupo$num>=12) #Se excluye todo lo mayor a 12 ya que cada nit tiene 3 periodos.

Departamentos = Departamentos$Departamento
Dep = datos$Departamento%in%Departamentos
datos_dep = datos[Dep,]

```

```{r echo=FALSE}
bxplot_gastos_dif = boxplot(datos_dep$proporcion~datos_dep$Departamento , 
        main = "Proporcion vs Departamento",
        xlab = "Periodos",
        ylab = "Proporcion",
        boxwex = 0.5,col="blue")
```
<div class=text-justify>
En el gráfico anterior podemos  ver que  las constructoras  de los departamentos como el Valle  y Santander tiene  proporciones altas, lo que  significa que  las  empresas en estas regiones tiene  costos
de  venta  similares a lo que son sus  ventas  totales dejando  pocos margenes  de  ganancia.
Por  el contrario en departamentos como Bogotá y Antioquia las  empresas tienen una  mayor  variabilidad en pero en su mayoría sus  ventas  superan ampliamente los costos en los que deben incurrir para vender.

A continuación, realizaremos un análisis de outliers,eliminaremos aquellas empresas  que para algunos de sus periodos tuvieron proporciones de costos de  ventas sobre ventas  inferiores al  30% , ya que  dadas las  condiciones  de  mercado no  es un dato confiable.
<div>

```{r include=FALSE}
library(tidyverse)

impute_outliers <- function(x, removeNA = TRUE){
  quantiles <- quantile(x, c(0.05, 0.95), na.rm = removeNA)
  x[x<quantiles[1]] <- mean(x, na.rm = removeNA)
  x[x>quantiles[2]] <- median(x, na.rm = removeNA)
  x
}

datos_16d   <- datos_dep %>%             # a partir de out.predict.garch  
  filter(datos_dep$periodo==2016)


out16d <- datos_16d %>%             # a partir de out.predict.garch  
  filter(datos_16d$proporcion <= quantile(datos_16d$proporcion, c(0.10)))


datos_17d   <- datos_dep %>%             # a partir de out.predict.garch  
  filter(datos_dep$periodo==2017)


out17d <- datos_17d %>%             # a partir de out.predict.garch  
  filter(datos_17d$proporcion <= quantile(datos_17d$proporcion, c(0.10)))


datos_18d   <- datos_dep %>%             # a partir de out.predict.garch  
  filter(datos_dep$periodo==2018)

out18d <- datos_18d %>%             # a partir de out.predict.garch  
  filter(datos_18d$proporcion <= quantile(datos_18d$proporcion, c(0.10)))


out16d = t(out16d$nit)
out17d = t(out17d$nit)
out18d = t(out18d$nit)

outliersd = distinct(as.data.frame(t(cbind(out16d,out17d,out18d))))
names(outliersd) = ("Nit_Out")


```

```{r include=FALSE}
`%ni%` <- Negate(`%in%`)
outd = datos_dep$nit%ni%outliersd$Nit_Out
datos_deps = datos_dep[outd,]
```

```{r echo=FALSE}
boxplot(datos_deps$proporcion~datos_deps$Departamento,
        main = "Proporcion vs periodo",
        xlab = "Periodos",
        ylab = "Proporcion",
        boxwex = 0.5,col="blue")

```
<div class=text-justify>
  Bajo el mismo razonamiento empleado en el primer enfoque, entrenaremos el modelo con todos los  nits y 
seleccionaremos  un 20% de ellos de los cuales  trendremos solo  dos periodos en el conjunto de entrenamiento, para emplear el periodo 3 como  base de  testing.

```{r include=FALSE}
datos_deps$nit = factor(datos_deps$nit)
datos_deps$Departamento = factor(datos_deps$Departamento)
datos_deps$periodo = factor(datos_deps$periodo,
                       levels = c("2016","2017","2018"),
                       labels = c(1,2,3))
```

```{r include=FALSE}

library(caTools)
set.seed(4)

nite = as.data.frame(unique(datos_deps$nit))

names(nite) = c("nit")

splitd = sample.split(nite$nit, SplitRatio = 0.8)


training_set_pd = subset(nite, splitd == TRUE)
training_set_pd = datos_deps$nit%in%training_set_pd$nit
training_set_pd = datos_deps[training_set_pd,]


testing_set_pd = subset(nite, splitd == FALSE)
testing_set_pd = datos_deps$nit%in%testing_set_pd$nit
testing_set_pd = datos_deps[testing_set_pd,]

periodo_testd = c(3)
testing_pd = testing_set_pd$periodo%in%periodo_testd
testing_set_d = testing_set_pd[testing_pd,]

periodo_traind = c(1,2)
train_pd = testing_set_pd$periodo%in%periodo_traind
train_pd = testing_set_pd[train_pd,]

training_set_pd = rbind(training_set_pd,train_pd)


```

```{r echo=FALSE}
cantidad2 <- as.data.frame(cbind(6,34))
names(cantidad2) = c("Cantidad empresas testeo","Cantidad empresas entrenamiento")

kable(cantidad) %>%
  kable_styling()%>%
  column_spec(1:1, bold = T) %>%
  row_spec(0, bold = T, color = "white", background = "#404d78")

```

##### <span style="color:#404d78"> **Planteamiento de modelos** </span>
<div class=text-justify>
  Como mencionabamos anteriormente, consideramos que dados los resultados anteriores podría ahondarse un poco más y tener las variables macroeconomicas a nivel de departamento, de tal manera que nos permitan aterrizar los comportamientos de las empresas en un entorno m´s regional y de esta manera ratificar la relación de los indicadores macroeconómicos para ello, abordaremos un nuevo enfoque para  explicar la proporción buscando  obtener un modelo más ajustado  y con un mejor  desempeño.
Después de realizar diferentes combinaciones encontramos 6 posibles modelos que con las variables macroeconómicas pueden también explicar la variable respuesta proporción.

```{r echo=FALSE}

library(nlme)

modelo1d <- lme(proporcion ~ Liquidez+tasa_desemp_dep+pib_dep+variacion_pib_dep+ipc_anio_dep+ingr_corr_dep+gastos_fun_dep+inflacion +tasa_int_prom+CHV+EC+ECG, data = training_set_pd, random = ~1|nit)

modelo2d <- lme(proporcion ~ tasa_desemp_dep+pib_dep+ingr_corr_dep, data = training_set_pd, random = ~1|nit)

modelo3d <- lme(proporcion ~ tasa_desemp_dep+pib_dep, data = training_set_pd, random = ~1|nit)

modelo4d <- lme(proporcion ~ tasa_desemp_dep+pib_dep+CHV , data = training_set_pd, random = ~1|nit)
AIC(modelo3d)

modelo5d <- lme(proporcion ~ CHV+EC+ECG, data = training_set_pd, random = ~1|nit)

modelo6d <- lme(proporcion ~ tasa_desemp_dep+pib_dep++ipc_anio_dep+inflacion, data = training_set_pd, random = ~1|nit)

Modelod <-  rbind("Modelo1d","Modelo2d","Modelo3d","Modelo4d","Modelo5d","Modelo6d")

AIC_Modelod <- rbind(round(AIC(modelo1d),2),
round(AIC(modelo2d),2),
round(AIC(modelo3d),2),
round(AIC(modelo4d),2),
round(AIC(modelo5d),2),
round(AIC(modelo6d),2))

BIC_Modelod <- rbind(round(BIC(modelo1d),2),
round(BIC(modelo2d),2),
round(BIC(modelo3d),2),
round(BIC(modelo4d),2),
round(BIC(modelo5d),2),
round(BIC(modelo6d),2))


estructurad<-rbind("Proporcion ~ liquidez+tasa_desemp_dep+pib_dep+variacion_pib_dep+ipc_anio_dep+ingr_corr_dep+gastos_fun_dep+inflacion +tasa_int_prom+CHV+EC+ECG+(1|nit)",
                   "Proporcion ~ tasa_desemp_dep+pib_dep+ingr_corr_dep+(1|nit)",
                   "Proporcion ~ tasa_desemp_dep+pib_dep+(1|nit)",
                   "Proporcion ~ PIB_Variacion+Tasa_Desempleo+(1|nit)",
                   "Proporcion ~ tasa_desemp_dep+pib_dep+CHV+(1|nit)",
                   "Proporcion ~ tasa_desemp_dep+pib_dep++ipc_anio_dep+inflacion+(1|nit)")

metricasd <- as.data.frame(cbind(Modelod,estructurad,AIC_Modelod,BIC_Modelod))
names(metricasd) = c("Modelo","Estructura","AIC","BIC")

kable(metricasd) %>%
  column_spec(1:1, bold = T) %>%
  row_spec(0, bold = T, color = "white", background = "#404d78")

```


```{r echo=FALSE}
summary(modelo3d)
anova(modelo3d)
```
En este caso el modelo 3 de acuerdo a la métrica de verosimilitud tiene un mejor desempeño, al validar sus valores P, la tasa de desempelo tiene el menor valor p que hemos encontrado al rededor de nuestro ejercio por lo cual se podría tratar de un muy buen indicio, sin embargo, probamos la capacidad predictiva para cada modelo y de esta manera generar la decisión basados en resultados globales.

```{r echo=FALSE}
prediccion1d	=	predict(modelo1d,testing_set_pd,level =1,allow.new.levels=T)
names(prediccion1d) = c("prediccion")
prediccion2d	=	predict(modelo2d,testing_set_pd,level =1,allow.new.levels=T)
names(prediccion2d) = c("prediccion")
prediccion3d	=	predict(modelo3d,testing_set_pd,level =1,allow.new.levels=T)
names(prediccion3d) = c("prediccion")
prediccion4d	=	predict(modelo4d,testing_set_pd,level =1,allow.new.levels=T)
names(prediccion4d) = c("prediccion")
prediccion5d	=	predict(modelo5d,testing_set_pd,level =1,allow.new.levels=T)
names(prediccion5d) = c("prediccion")
prediccion6d	=	predict(modelo6d,testing_set_pd,level =1,allow.new.levels=T)
names(prediccion6d) = c("prediccion")

library(MLmetrics)

prediccion1d	=	predict(modelo1d,testing_set_d,level =1,allow.new.levels=T)
predichos1d	=	cbind(testing_set_d$proporcion,as.data.frame(prediccion1d))
names(predichos1d)	=	c("Datos1","Prediccion1")

prediccion2d	=	predict(modelo2d,testing_set_d,level =1,allow.new.levels=T)
predichos2d	=	cbind(testing_set_d$proporcion,as.data.frame(prediccion2d))
names(predichos2d)	=	c("Datos2","Prediccion2")

prediccion3d	=	predict(modelo3d,testing_set_d,level =1,allow.new.levels=T)
predichos3d	=	cbind(testing_set_d$proporcion,as.data.frame(prediccion3d))
names(predichos3d)	=	c("Datos3","Prediccion3")

prediccion4d	=	predict(modelo4d,testing_set_d,level =1,allow.new.levels=T)
predichos4d	=	cbind(testing_set_d$proporcion,as.data.frame(prediccion4d))
names(predichos4d)	=	c("Datos4","Prediccion4")

prediccion5d	=	predict(modelo5d,testing_set_d,level =1,allow.new.levels=T)
predichos5d	=	cbind(testing_set_d$proporcion,as.data.frame(prediccion5d))
names(predichos5d)	=	c("Datos5","Prediccion5")

prediccion6d	=	predict(modelo6d,testing_set_d,level =1,allow.new.levels=T)
predichos6d	=	cbind(testing_set_d$proporcion,as.data.frame(prediccion6d))
names(predichos6d)	=	c("Datos6","Prediccion6")


MSE1d<-MSE(predichos1d$Prediccion1,predichos1d$Datos1)
RMSE1d<-RMSE(predichos1d$Prediccion1,predichos1d$Datos1)
MAPE1d<-MAPE(predichos1d$Prediccion1,predichos1d$Datos1)

MSE2d<-MSE(predichos2d$Prediccion2,predichos2d$Datos2)
RMSE2d<-RMSE(predichos2d$Prediccion2,predichos2d$Datos2)
MAPE2d<-MAPE(predichos2d$Prediccion2,predichos2d$Datos2)

MSE3d<-MSE(predichos3d$Prediccion3,predichos3d$Datos3)
RMSE3d<-RMSE(predichos3d$Prediccion3,predichos3d$Datos3)
MAPE3d<-MAPE(predichos3d$Prediccion3,predichos3d$Datos3)

MSE4d<-MSE(predichos4d$Prediccion4,predichos4d$Datos4)
RMSE4d<-RMSE(predichos4d$Prediccion4,predichos4d$Datos4)
MAPE4d<-MAPE(predichos4d$Prediccion4,predichos4d$Datos4)

MSE5d<-MSE(predichos5d$Prediccion5,predichos5d$Datos5)
RMSE5d<-RMSE(predichos5d$Prediccion5,predichos5d$Datos5)
MAPE5d<-MAPE(predichos5d$Prediccion5,predichos5d$Datos5)

MSE6d<-MSE(predichos6d$Prediccion6,predichos6d$Datos6)
RMSE6d<-RMSE(predichos6d$Prediccion6,predichos6d$Datos6)
MAPE6d<-MAPE(predichos6d$Prediccion6,predichos6d$Datos6)

RMSEd <- rbind(round(RMSE1d,6),
round(RMSE2d,6),
round(RMSE3d,6),
round(RMSE4d,6),
round(RMSE5d,6),
round(RMSE6d,6))

MSEd <- rbind(round(MSE1d,6),
round(MSE2d,6),
round(MSE3d,6),
round(MSE4d,6),
round(MSE5d,6),
round(MSE6d,6))

MAPEd <- rbind(round(MAPE1d,6),
round(MAPE2d,6),
round(MAPE3d,6),
round(MAPE4d,6),
round(MAPE5d,6),
round(MAPE6d,6))


metricas_predicciond <- as.data.frame(cbind(MSEd,RMSEd,MAPEd))
names(metricas_predicciond) = c("MSE","RMSE","MAPE")

metricas_consolidadasd <- as.data.frame(cbind(metricasd,metricas_predicciond))

kable(metricas_consolidadasd) %>%
  kable_styling()%>%
  column_spec(1:1, bold = T) %>%
  row_spec(0, bold = T, color = "white", background = "#404d78")

```

De acuerdo a las metricas consolidadas evidenciamos qeue el modelo 3 tiene un menor AIC sin embargo en terminos de MAPE que corresponde al al error absoluto porcentual medio no es el menor, siendolo el modelo2d por 0,006965 de diferencia, sin embargo se evidencia que indicadores como la tasa de desempleo y el PIB continuan predominando como variables explicativas en nuestros modelos.

```{r include=TRUE}
plot(modelo3d,type = c("p", "smooth"))

```

```{r include=TRUE}
Fit <- fitted(modelo3d)
Res <- residuals(modelo3d, type = "normalized") 
par(mfrow = c(2, 2))
plot(Res ~ Fit, xlab = "Fitted values", ylab = "Residuals", main = "Residuals vs. fitted")
abline(h = 0)

hist(Res, main = "Histogram of residuals", xlab = "Residuals")
qqnorm(Res)
qqline(Res)

```

Vemos que al igual que  con el primer enfoque los residuales siguen sin tener  un comportamiento completamente aleatorio, sin embargo, las  medidas ajuste son mucho mejores que  para cualquier  modelo  entrenado hasta este lugar, por lo cual este modelo  permite  caracterizar de  mejor  la relación de la  propoción con las  variables macroeconomicas
Veamos ahora  el ajuste de este modelo por empresa.
```{r include=TRUE}
plot(modelo3d, proporcion ~ fitted(.) | nit, abline = c(0,1))
```

##### <span style="color:#404d78"> **Descripción del modelo seleccionado** </span>

La ecuación de  nuestro modelo  seleccionado  para este caso es la  siguiente es la siguiente:

$$Proporcion_{i t}=0.8815924+0.1193180*tasa.desempleo.departamental{it}-0.0232007*PIB.departamental_{it}$$
De ella se puede interpretar que por incremento del 10.5% de la tasa de desempleo departamental,la  proporción aumenta en un 0.11 para la empresa i en el periodo t.Una  disminución de  1000000000 en en PIB departamental,disminuye en un 0.02 la  proporción de las empresa  i en el periodo t.

### **V.Valoración del trabajo  y conclusiones**

##### <span style="color:#404d78"> **Valoración** </span>

* Realizar este  tipo de ejercicios implican  una  gran cantidad  de  tiempo  invertido  para llevarlo a  termino, por eso  en nuestra percepción los  esfuerzos en una escala de 1-5 para este  ejercicio en particular es:  (3.5) la consolidación de la  base de datos  dado que su operatividad genera  consumo de gran parte del tiempo,la postulación de modelos podriamos cuantificarla en un (5) ya que, para construirlos fue necesario  buscar multiples bibliografias  que  nos ayudaran a entender  los  conceptos bajo los  cuales funcionada el algoritmo, la transformación de cifras implicó indagar más en el contexto del problema  para  asi realizar las  que se  consideraban procedian en cada caso por consideramos que su calificacion sería un (4), por último  y no menos importante la realización del informe, implica exponer los resultados de tal manera que  sean comprensibles para el lector por lo tanto consideramos que una poderación acorde  al esfuerzo para este es (3.5).



##### <span style="color:#404d78"> **Repositorio** </span>

El código realizado para la ejecución del presente trabajo se encuentra en el [ repositiorio git](https://github.com/karenEAFIT/Metodos_Estadisticos) *https://github.com/karenEAFIT/Metodos_Estadisticos**, en este repositorio se encuentraran el código con el cual fue desarrollado el presente trabajo, el código para la ejecución del informe y los set de datos utilizados para cumplir con el objetivo del mismo.


##### <span style="color:#404d78"> **Conclusiones** </span>
* Para nuestro ejercicio a nivel general el PIB y la tasa de desempleo son dos factores macroeconómicos que inciden en la proporción,por lo cual esto puede generar un contexto del mercado para las empresas y les permitirá tomar  decisiones  antecipadamente  según el entorno nacional y local.
*Se  evidenció quelos modelos mixtos dan una buena solución a problematicas  de este tipo donde  se involucre información a diferentes  escalas  (empresas, nación, departamento).
Sin embargo, tambien  fue  claro  que  las  variables  locales  permites  una  mejor  caracterización, debido a que la realidad  local  puede  variar sustancialmente  de la realidad  nacional.


